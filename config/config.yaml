# Details about llm
# Fall back model -> llama-3.3-70b-versatile
# model_name: "openai/gpt-oss-120b"
# llm:
#     groq:
#       provider: "groq"
#       primary_model: "openai/gpt-oss-120b"
#       fallback_model: "llama3-70b-8192"

#  Updated configuration for llm with new model names and added OpenAI section
llm:
  groq:
    provider: "groq"
    model_name: "llama-3.3-70b-versatile"  # Current production model
    fallback_model: "llama-3.1-8b-instant"  # Fast, efficient fallback
  openai:
    provider: "openai"
    model_name: "gpt-4o-mini"  # Cost-efficient, widely available
    fallback_model: "gpt-4o"  # More powerful fallback

# Root level for backward compatibility
model_name: "llama-3.3-70b-versatile"